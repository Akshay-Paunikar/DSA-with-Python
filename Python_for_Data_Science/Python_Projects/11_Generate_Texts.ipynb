{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a8181ef-fa8e-41e7-a41c-e8f6a436b82d",
   "metadata": {},
   "source": [
    "<h3>Generate Text using Python</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f63626-a238-4bdc-bc8a-4633b3c50d36",
   "metadata": {},
   "source": [
    "Text generation involves generating text using machine learning techniques. The purpose of text generation is to automatically generate text that is indistinguishable from a text written by a human.\n",
    "\n",
    "<b>What is GPT-2 Model?</b>\n",
    "\n",
    "GPT-2 stands for Generative Pre-trained Transformer 2. It is an open-source Natural Language Processing model created by OpenAI. It can generate paragraphs of text with state of the art performance on many language benchmarks. It is also used for machine translation, question answering, and text summarization.\n",
    "\n",
    "To use the GPT-2 model to generate text using Python, you need to install the Transformers library in Python. It can be easily installed using the pip command on your command prompt or terminal as mentioned below - :\n",
    "\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c33ef49a-241a-49de-afab-b5d67b20c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f9e890-6be8-4fe2-a86c-f3c3422a0394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\Deep_Learning\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "config.json: 100%|██████████| 665/665 [00:00<00:00, 244kB/s]\n",
      "d:\\anaconda\\envs\\Deep_Learning\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\LENOVO\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "model.safetensors: 100%|██████████| 548M/548M [01:53<00:00, 4.85MB/s] \n",
      "generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 25.8kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 1.85kB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.54MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 649kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:01<00:00, 1.35MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model = pipeline(\"text-generation\", model = \"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9200402-e6c4-4a27-93c1-ea9e9bd18868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "sentence = model(\"Hello my name Bryan Mills, I am a former Navy Seal Commander\",\n",
    "                do_sample = True, top_k = 50, temperature = 0.9, max_length=100, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6475b60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name Bryan Mills, I am a former Navy Seal Commander in the Pacific. I am a Marine on your ship. I am the man who helped secure the world's most secure nuclear weapons. I am the man who gave the world the first fully hydrogen bomb.\n",
      "\n",
      "Citizens of the United States. I am a former Navy Seal Commander. I am an international expert. I am the most recent National Security Advisor to the Trump administration. I am the most recent Presidential candidate to call for\n"
     ]
    }
   ],
   "source": [
    "for i in sentence:\n",
    "  print(i[\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
